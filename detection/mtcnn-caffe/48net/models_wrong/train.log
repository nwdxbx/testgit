I0620 16:48:24.860612  1742 caffe.cpp:218] Using GPUs 0
I0620 16:48:24.890008  1742 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0620 16:48:25.117094  1742 solver.cpp:44] Initializing solver from parameters: 
base_lr: 1e-05
display: 5000
max_iter: 20000
lr_policy: "step"
gamma: 0.8
momentum: 0.9
weight_decay: 0.004
stepsize: 30000
snapshot: 5000
snapshot_prefix: "./models/"
solver_mode: GPU
device_id: 0
net: "train48.prototxt"
train_state {
  level: 0
  stage: ""
}
I0620 16:48:25.117251  1742 solver.cpp:87] Creating training net from net file: train48.prototxt
I0620 16:48:25.117720  1742 net.cpp:51] Initializing net from parameters: 
name: "face_48"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "PythonLayer"
  type: "Python"
  top: "data"
  top: "label"
  top: "roi"
  top: "pts"
  python_param {
    module: "pythonLayer"
    layer: "Data_Layer_train"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6-1"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_bridge"
  type: "Python"
  bottom: "conv6-1"
  bottom: "label"
  top: "conv6-1-valid"
  top: "label-valid"
  python_param {
    module: "pythonLayer"
    layer: "cls_Layer"
  }
}
layer {
  name: "ClassifyLoss"
  type: "SoftmaxWithLoss"
  bottom: "conv6-1-valid"
  bottom: "label-valid"
  top: "ClassifyLoss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "cls_Acc"
  type: "Accuracy"
  bottom: "conv6-1-valid"
  bottom: "label-valid"
  top: "cls_Acc"
  include {
    phase: TRAIN
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "RegressionLoss"
  type: "Python"
  bottom: "conv6-2"
  bottom: "roi"
  top: "RegressionLoss"
  loss_weight: 0.5
  python_param {
    module: "pythonLayer"
    layer: "regression_Layer"
  }
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "LandmarkLoss"
  type: "Python"
  bottom: "conv6-3"
  bottom: "pts"
  top: "LandmarkLoss"
  loss_weight: 1
  python_param {
    module: "pythonLayer"
    layer: "regression_Layer"
  }
}
I0620 16:48:25.118006  1742 layer_factory.hpp:77] Creating layer PythonLayer
I0620 16:48:25.543711  1742 net.cpp:84] Creating Layer PythonLayer
I0620 16:48:25.543748  1742 net.cpp:380] PythonLayer -> data
I0620 16:48:25.543777  1742 net.cpp:380] PythonLayer -> label
I0620 16:48:25.543787  1742 net.cpp:380] PythonLayer -> roi
I0620 16:48:25.543793  1742 net.cpp:380] PythonLayer -> pts
Start Reading Classify Data into Memory...

20000  Classify Data have been read into Memory...
Start Reading Regression Data into Memory...

15000  Regression Data have been read into Memory...
Start Reading pts-regression Data into Memory...

10000  pts-regression Data have been read into Memory...
I0620 16:52:18.237092  1742 net.cpp:122] Setting up PythonLayer
I0620 16:52:18.237519  1742 net.cpp:129] Top shape: 64 3 48 48 (442368)
I0620 16:52:18.237542  1742 net.cpp:129] Top shape: 64 1 (64)
I0620 16:52:18.237560  1742 net.cpp:129] Top shape: 64 4 (256)
I0620 16:52:18.237565  1742 net.cpp:129] Top shape: 64 10 (640)
I0620 16:52:18.237582  1742 net.cpp:137] Memory required for data: 1773312
I0620 16:52:18.237603  1742 layer_factory.hpp:77] Creating layer conv1
I0620 16:52:18.237637  1742 net.cpp:84] Creating Layer conv1
I0620 16:52:18.237643  1742 net.cpp:406] conv1 <- data
I0620 16:52:18.237668  1742 net.cpp:380] conv1 -> conv1
I0620 16:52:18.574546  1742 net.cpp:122] Setting up conv1
I0620 16:52:18.574581  1742 net.cpp:129] Top shape: 64 32 46 46 (4333568)
I0620 16:52:18.574586  1742 net.cpp:137] Memory required for data: 19107584
I0620 16:52:18.574648  1742 layer_factory.hpp:77] Creating layer prelu1
I0620 16:52:18.574671  1742 net.cpp:84] Creating Layer prelu1
I0620 16:52:18.574674  1742 net.cpp:406] prelu1 <- conv1
I0620 16:52:18.574692  1742 net.cpp:367] prelu1 -> conv1 (in-place)
I0620 16:52:18.575337  1742 net.cpp:122] Setting up prelu1
I0620 16:52:18.575346  1742 net.cpp:129] Top shape: 64 32 46 46 (4333568)
I0620 16:52:18.575350  1742 net.cpp:137] Memory required for data: 36441856
I0620 16:52:18.575371  1742 layer_factory.hpp:77] Creating layer pool1
I0620 16:52:18.575376  1742 net.cpp:84] Creating Layer pool1
I0620 16:52:18.575381  1742 net.cpp:406] pool1 <- conv1
I0620 16:52:18.575400  1742 net.cpp:380] pool1 -> pool1
I0620 16:52:18.575446  1742 net.cpp:122] Setting up pool1
I0620 16:52:18.575464  1742 net.cpp:129] Top shape: 64 32 23 23 (1083392)
I0620 16:52:18.575467  1742 net.cpp:137] Memory required for data: 40775424
I0620 16:52:18.575484  1742 layer_factory.hpp:77] Creating layer conv2
I0620 16:52:18.575494  1742 net.cpp:84] Creating Layer conv2
I0620 16:52:18.575496  1742 net.cpp:406] conv2 <- pool1
I0620 16:52:18.575501  1742 net.cpp:380] conv2 -> conv2
I0620 16:52:18.577208  1742 net.cpp:122] Setting up conv2
I0620 16:52:18.577216  1742 net.cpp:129] Top shape: 64 64 21 21 (1806336)
I0620 16:52:18.577234  1742 net.cpp:137] Memory required for data: 48000768
I0620 16:52:18.577242  1742 layer_factory.hpp:77] Creating layer prelu2
I0620 16:52:18.577247  1742 net.cpp:84] Creating Layer prelu2
I0620 16:52:18.577251  1742 net.cpp:406] prelu2 <- conv2
I0620 16:52:18.577255  1742 net.cpp:367] prelu2 -> conv2 (in-place)
I0620 16:52:18.577368  1742 net.cpp:122] Setting up prelu2
I0620 16:52:18.577373  1742 net.cpp:129] Top shape: 64 64 21 21 (1806336)
I0620 16:52:18.577390  1742 net.cpp:137] Memory required for data: 55226112
I0620 16:52:18.577394  1742 layer_factory.hpp:77] Creating layer pool2
I0620 16:52:18.577414  1742 net.cpp:84] Creating Layer pool2
I0620 16:52:18.577416  1742 net.cpp:406] pool2 <- conv2
I0620 16:52:18.577419  1742 net.cpp:380] pool2 -> pool2
I0620 16:52:18.577457  1742 net.cpp:122] Setting up pool2
I0620 16:52:18.577462  1742 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0620 16:52:18.577464  1742 net.cpp:137] Memory required for data: 56864512
I0620 16:52:18.577479  1742 layer_factory.hpp:77] Creating layer conv3
I0620 16:52:18.577484  1742 net.cpp:84] Creating Layer conv3
I0620 16:52:18.577487  1742 net.cpp:406] conv3 <- pool2
I0620 16:52:18.577505  1742 net.cpp:380] conv3 -> conv3
I0620 16:52:18.578493  1742 net.cpp:122] Setting up conv3
I0620 16:52:18.578502  1742 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0620 16:52:18.578521  1742 net.cpp:137] Memory required for data: 57913088
I0620 16:52:18.578526  1742 layer_factory.hpp:77] Creating layer prelu3
I0620 16:52:18.578543  1742 net.cpp:84] Creating Layer prelu3
I0620 16:52:18.578546  1742 net.cpp:406] prelu3 <- conv3
I0620 16:52:18.578549  1742 net.cpp:367] prelu3 -> conv3 (in-place)
I0620 16:52:18.578655  1742 net.cpp:122] Setting up prelu3
I0620 16:52:18.578660  1742 net.cpp:129] Top shape: 64 64 8 8 (262144)
I0620 16:52:18.578663  1742 net.cpp:137] Memory required for data: 58961664
I0620 16:52:18.578668  1742 layer_factory.hpp:77] Creating layer pool3
I0620 16:52:18.578673  1742 net.cpp:84] Creating Layer pool3
I0620 16:52:18.578692  1742 net.cpp:406] pool3 <- conv3
I0620 16:52:18.578709  1742 net.cpp:380] pool3 -> pool3
I0620 16:52:18.578748  1742 net.cpp:122] Setting up pool3
I0620 16:52:18.578753  1742 net.cpp:129] Top shape: 64 64 4 4 (65536)
I0620 16:52:18.578755  1742 net.cpp:137] Memory required for data: 59223808
I0620 16:52:18.578758  1742 layer_factory.hpp:77] Creating layer conv4
I0620 16:52:18.578775  1742 net.cpp:84] Creating Layer conv4
I0620 16:52:18.578778  1742 net.cpp:406] conv4 <- pool3
I0620 16:52:18.578780  1742 net.cpp:380] conv4 -> conv4
I0620 16:52:18.580029  1742 net.cpp:122] Setting up conv4
I0620 16:52:18.580052  1742 net.cpp:129] Top shape: 64 128 3 3 (73728)
I0620 16:52:18.580055  1742 net.cpp:137] Memory required for data: 59518720
I0620 16:52:18.580060  1742 layer_factory.hpp:77] Creating layer prelu4
I0620 16:52:18.580080  1742 net.cpp:84] Creating Layer prelu4
I0620 16:52:18.580083  1742 net.cpp:406] prelu4 <- conv4
I0620 16:52:18.580087  1742 net.cpp:367] prelu4 -> conv4 (in-place)
I0620 16:52:18.580147  1742 net.cpp:122] Setting up prelu4
I0620 16:52:18.580152  1742 net.cpp:129] Top shape: 64 128 3 3 (73728)
I0620 16:52:18.580168  1742 net.cpp:137] Memory required for data: 59813632
I0620 16:52:18.580171  1742 layer_factory.hpp:77] Creating layer conv5
I0620 16:52:18.580190  1742 net.cpp:84] Creating Layer conv5
I0620 16:52:18.580193  1742 net.cpp:406] conv5 <- conv4
I0620 16:52:18.580198  1742 net.cpp:380] conv5 -> conv5
I0620 16:52:18.581369  1742 net.cpp:122] Setting up conv5
I0620 16:52:18.581375  1742 net.cpp:129] Top shape: 64 256 (16384)
I0620 16:52:18.581377  1742 net.cpp:137] Memory required for data: 59879168
I0620 16:52:18.581395  1742 layer_factory.hpp:77] Creating layer drop5
I0620 16:52:18.581401  1742 net.cpp:84] Creating Layer drop5
I0620 16:52:18.581404  1742 net.cpp:406] drop5 <- conv5
I0620 16:52:18.581408  1742 net.cpp:367] drop5 -> conv5 (in-place)
I0620 16:52:18.581439  1742 net.cpp:122] Setting up drop5
I0620 16:52:18.581441  1742 net.cpp:129] Top shape: 64 256 (16384)
I0620 16:52:18.581444  1742 net.cpp:137] Memory required for data: 59944704
I0620 16:52:18.581445  1742 layer_factory.hpp:77] Creating layer prelu5
I0620 16:52:18.581449  1742 net.cpp:84] Creating Layer prelu5
I0620 16:52:18.581451  1742 net.cpp:406] prelu5 <- conv5
I0620 16:52:18.581454  1742 net.cpp:367] prelu5 -> conv5 (in-place)
I0620 16:52:18.581519  1742 net.cpp:122] Setting up prelu5
I0620 16:52:18.581523  1742 net.cpp:129] Top shape: 64 256 (16384)
I0620 16:52:18.581526  1742 net.cpp:137] Memory required for data: 60010240
I0620 16:52:18.581528  1742 layer_factory.hpp:77] Creating layer conv5_prelu5_0_split
I0620 16:52:18.581532  1742 net.cpp:84] Creating Layer conv5_prelu5_0_split
I0620 16:52:18.581534  1742 net.cpp:406] conv5_prelu5_0_split <- conv5
I0620 16:52:18.581537  1742 net.cpp:380] conv5_prelu5_0_split -> conv5_prelu5_0_split_0
I0620 16:52:18.581542  1742 net.cpp:380] conv5_prelu5_0_split -> conv5_prelu5_0_split_1
I0620 16:52:18.581547  1742 net.cpp:380] conv5_prelu5_0_split -> conv5_prelu5_0_split_2
I0620 16:52:18.581590  1742 net.cpp:122] Setting up conv5_prelu5_0_split
I0620 16:52:18.581595  1742 net.cpp:129] Top shape: 64 256 (16384)
I0620 16:52:18.581598  1742 net.cpp:129] Top shape: 64 256 (16384)
I0620 16:52:18.581601  1742 net.cpp:129] Top shape: 64 256 (16384)
I0620 16:52:18.581604  1742 net.cpp:137] Memory required for data: 60206848
I0620 16:52:18.581607  1742 layer_factory.hpp:77] Creating layer conv6-1
I0620 16:52:18.581612  1742 net.cpp:84] Creating Layer conv6-1
I0620 16:52:18.581616  1742 net.cpp:406] conv6-1 <- conv5_prelu5_0_split_0
I0620 16:52:18.581621  1742 net.cpp:380] conv6-1 -> conv6-1
I0620 16:52:18.581718  1742 net.cpp:122] Setting up conv6-1
I0620 16:52:18.581722  1742 net.cpp:129] Top shape: 64 2 (128)
I0620 16:52:18.581737  1742 net.cpp:137] Memory required for data: 60207360
I0620 16:52:18.581744  1742 layer_factory.hpp:77] Creating layer cls_bridge
I0620 16:52:18.581785  1742 net.cpp:84] Creating Layer cls_bridge
I0620 16:52:18.581789  1742 net.cpp:406] cls_bridge <- conv6-1
I0620 16:52:18.581802  1742 net.cpp:406] cls_bridge <- label
I0620 16:52:18.581807  1742 net.cpp:380] cls_bridge -> conv6-1-valid
I0620 16:52:18.581815  1742 net.cpp:380] cls_bridge -> label-valid
I0620 16:52:18.581912  1742 net.cpp:122] Setting up cls_bridge
I0620 16:52:18.581918  1742 net.cpp:129] Top shape: 64 2 (128)
I0620 16:52:18.581923  1742 net.cpp:129] Top shape: 64 1 (64)
I0620 16:52:18.581925  1742 net.cpp:137] Memory required for data: 60208128
I0620 16:52:18.581928  1742 layer_factory.hpp:77] Creating layer conv6-1-valid_cls_bridge_0_split
I0620 16:52:18.581933  1742 net.cpp:84] Creating Layer conv6-1-valid_cls_bridge_0_split
I0620 16:52:18.581938  1742 net.cpp:406] conv6-1-valid_cls_bridge_0_split <- conv6-1-valid
I0620 16:52:18.581941  1742 net.cpp:380] conv6-1-valid_cls_bridge_0_split -> conv6-1-valid_cls_bridge_0_split_0
I0620 16:52:18.581948  1742 net.cpp:380] conv6-1-valid_cls_bridge_0_split -> conv6-1-valid_cls_bridge_0_split_1
I0620 16:52:18.581972  1742 net.cpp:122] Setting up conv6-1-valid_cls_bridge_0_split
I0620 16:52:18.581977  1742 net.cpp:129] Top shape: 64 2 (128)
I0620 16:52:18.581980  1742 net.cpp:129] Top shape: 64 2 (128)
I0620 16:52:18.581984  1742 net.cpp:137] Memory required for data: 60209152
I0620 16:52:18.581986  1742 layer_factory.hpp:77] Creating layer label-valid_cls_bridge_1_split
I0620 16:52:18.581991  1742 net.cpp:84] Creating Layer label-valid_cls_bridge_1_split
I0620 16:52:18.581995  1742 net.cpp:406] label-valid_cls_bridge_1_split <- label-valid
I0620 16:52:18.581998  1742 net.cpp:380] label-valid_cls_bridge_1_split -> label-valid_cls_bridge_1_split_0
I0620 16:52:18.582003  1742 net.cpp:380] label-valid_cls_bridge_1_split -> label-valid_cls_bridge_1_split_1
I0620 16:52:18.582027  1742 net.cpp:122] Setting up label-valid_cls_bridge_1_split
I0620 16:52:18.582031  1742 net.cpp:129] Top shape: 64 1 (64)
I0620 16:52:18.582036  1742 net.cpp:129] Top shape: 64 1 (64)
I0620 16:52:18.582037  1742 net.cpp:137] Memory required for data: 60209664
I0620 16:52:18.582041  1742 layer_factory.hpp:77] Creating layer ClassifyLoss
I0620 16:52:18.582046  1742 net.cpp:84] Creating Layer ClassifyLoss
I0620 16:52:18.582048  1742 net.cpp:406] ClassifyLoss <- conv6-1-valid_cls_bridge_0_split_0
I0620 16:52:18.582052  1742 net.cpp:406] ClassifyLoss <- label-valid_cls_bridge_1_split_0
I0620 16:52:18.582057  1742 net.cpp:380] ClassifyLoss -> ClassifyLoss
I0620 16:52:18.582072  1742 layer_factory.hpp:77] Creating layer ClassifyLoss
I0620 16:52:18.582279  1742 net.cpp:122] Setting up ClassifyLoss
I0620 16:52:18.582285  1742 net.cpp:129] Top shape: (1)
I0620 16:52:18.582289  1742 net.cpp:132]     with loss weight 1
I0620 16:52:18.582303  1742 net.cpp:137] Memory required for data: 60209668
I0620 16:52:18.582305  1742 layer_factory.hpp:77] Creating layer cls_Acc
I0620 16:52:18.582310  1742 net.cpp:84] Creating Layer cls_Acc
I0620 16:52:18.582314  1742 net.cpp:406] cls_Acc <- conv6-1-valid_cls_bridge_0_split_1
I0620 16:52:18.582317  1742 net.cpp:406] cls_Acc <- label-valid_cls_bridge_1_split_1
I0620 16:52:18.582321  1742 net.cpp:380] cls_Acc -> cls_Acc
I0620 16:52:18.582329  1742 net.cpp:122] Setting up cls_Acc
I0620 16:52:18.582334  1742 net.cpp:129] Top shape: (1)
I0620 16:52:18.582336  1742 net.cpp:137] Memory required for data: 60209672
I0620 16:52:18.582339  1742 layer_factory.hpp:77] Creating layer conv6-2
I0620 16:52:18.582343  1742 net.cpp:84] Creating Layer conv6-2
I0620 16:52:18.582347  1742 net.cpp:406] conv6-2 <- conv5_prelu5_0_split_1
I0620 16:52:18.582351  1742 net.cpp:380] conv6-2 -> conv6-2
I0620 16:52:18.582424  1742 net.cpp:122] Setting up conv6-2
I0620 16:52:18.582429  1742 net.cpp:129] Top shape: 64 4 (256)
I0620 16:52:18.582432  1742 net.cpp:137] Memory required for data: 60210696
I0620 16:52:18.582437  1742 layer_factory.hpp:77] Creating layer RegressionLoss
I0620 16:52:18.582470  1742 net.cpp:84] Creating Layer RegressionLoss
I0620 16:52:18.582474  1742 net.cpp:406] RegressionLoss <- conv6-2
I0620 16:52:18.582491  1742 net.cpp:406] RegressionLoss <- roi
I0620 16:52:18.582520  1742 net.cpp:380] RegressionLoss -> RegressionLoss
I0620 16:52:18.582619  1742 net.cpp:122] Setting up RegressionLoss
I0620 16:52:18.582626  1742 net.cpp:129] Top shape: 1 (1)
I0620 16:52:18.582643  1742 net.cpp:132]     with loss weight 0.5
I0620 16:52:18.582648  1742 net.cpp:137] Memory required for data: 60210700
I0620 16:52:18.582651  1742 layer_factory.hpp:77] Creating layer conv6-3
I0620 16:52:18.582657  1742 net.cpp:84] Creating Layer conv6-3
I0620 16:52:18.582661  1742 net.cpp:406] conv6-3 <- conv5_prelu5_0_split_2
I0620 16:52:18.582666  1742 net.cpp:380] conv6-3 -> conv6-3
I0620 16:52:18.582772  1742 net.cpp:122] Setting up conv6-3
I0620 16:52:18.582777  1742 net.cpp:129] Top shape: 64 10 (640)
I0620 16:52:18.582792  1742 net.cpp:137] Memory required for data: 60213260
I0620 16:52:18.582797  1742 layer_factory.hpp:77] Creating layer LandmarkLoss
I0620 16:52:18.582810  1742 net.cpp:84] Creating Layer LandmarkLoss
I0620 16:52:18.582814  1742 net.cpp:406] LandmarkLoss <- conv6-3
I0620 16:52:18.582819  1742 net.cpp:406] LandmarkLoss <- pts
I0620 16:52:18.582837  1742 net.cpp:380] LandmarkLoss -> LandmarkLoss
I0620 16:52:18.582921  1742 net.cpp:122] Setting up LandmarkLoss
I0620 16:52:18.582928  1742 net.cpp:129] Top shape: 1 (1)
I0620 16:52:18.582945  1742 net.cpp:132]     with loss weight 1
I0620 16:52:18.582949  1742 net.cpp:137] Memory required for data: 60213264
I0620 16:52:18.582952  1742 net.cpp:198] LandmarkLoss needs backward computation.
I0620 16:52:18.582959  1742 net.cpp:198] conv6-3 needs backward computation.
I0620 16:52:18.582962  1742 net.cpp:198] RegressionLoss needs backward computation.
I0620 16:52:18.582965  1742 net.cpp:198] conv6-2 needs backward computation.
I0620 16:52:18.582968  1742 net.cpp:200] cls_Acc does not need backward computation.
I0620 16:52:18.582972  1742 net.cpp:198] ClassifyLoss needs backward computation.
I0620 16:52:18.582975  1742 net.cpp:200] label-valid_cls_bridge_1_split does not need backward computation.
I0620 16:52:18.582979  1742 net.cpp:198] conv6-1-valid_cls_bridge_0_split needs backward computation.
I0620 16:52:18.582983  1742 net.cpp:198] cls_bridge needs backward computation.
I0620 16:52:18.582986  1742 net.cpp:198] conv6-1 needs backward computation.
I0620 16:52:18.582989  1742 net.cpp:198] conv5_prelu5_0_split needs backward computation.
I0620 16:52:18.582993  1742 net.cpp:198] prelu5 needs backward computation.
I0620 16:52:18.582995  1742 net.cpp:198] drop5 needs backward computation.
I0620 16:52:18.582998  1742 net.cpp:198] conv5 needs backward computation.
I0620 16:52:18.583001  1742 net.cpp:198] prelu4 needs backward computation.
I0620 16:52:18.583004  1742 net.cpp:198] conv4 needs backward computation.
I0620 16:52:18.583008  1742 net.cpp:198] pool3 needs backward computation.
I0620 16:52:18.583010  1742 net.cpp:198] prelu3 needs backward computation.
I0620 16:52:18.583026  1742 net.cpp:198] conv3 needs backward computation.
I0620 16:52:18.583029  1742 net.cpp:198] pool2 needs backward computation.
I0620 16:52:18.583032  1742 net.cpp:198] prelu2 needs backward computation.
I0620 16:52:18.583034  1742 net.cpp:198] conv2 needs backward computation.
I0620 16:52:18.583039  1742 net.cpp:198] pool1 needs backward computation.
I0620 16:52:18.583041  1742 net.cpp:198] prelu1 needs backward computation.
I0620 16:52:18.583045  1742 net.cpp:198] conv1 needs backward computation.
I0620 16:52:18.583047  1742 net.cpp:200] PythonLayer does not need backward computation.
I0620 16:52:18.583051  1742 net.cpp:242] This network produces output ClassifyLoss
I0620 16:52:18.583055  1742 net.cpp:242] This network produces output LandmarkLoss
I0620 16:52:18.583057  1742 net.cpp:242] This network produces output RegressionLoss
I0620 16:52:18.583060  1742 net.cpp:242] This network produces output cls_Acc
I0620 16:52:18.583076  1742 net.cpp:255] Network initialization done.
I0620 16:52:18.583119  1742 solver.cpp:56] Solver scaffolding done.
I0620 16:52:18.583623  1742 caffe.cpp:155] Finetuning from ./48net.caffemodel
I0620 16:52:18.590653  1742 net.cpp:744] Ignoring source layer data48
I0620 16:52:18.590683  1742 net.cpp:744] Ignoring source layer slicer_label
I0620 16:52:18.590685  1742 net.cpp:744] Ignoring source layer label1_slicer_label_0_split
I0620 16:52:18.590903  1742 net.cpp:744] Ignoring source layer conv6-1_conv6-1_0_split
I0620 16:52:18.590912  1742 net.cpp:744] Ignoring source layer loss1
I0620 16:52:18.590914  1742 net.cpp:744] Ignoring source layer accuracy1
I0620 16:52:18.590916  1742 net.cpp:744] Ignoring source layer loss2
I0620 16:52:18.590919  1742 net.cpp:744] Ignoring source layer loss3
I0620 16:52:18.590966  1742 caffe.cpp:248] Starting Optimization
I0620 16:52:18.590984  1742 solver.cpp:272] Solving face_48
I0620 16:52:18.590986  1742 solver.cpp:273] Learning Rate Policy: step
I0620 16:52:18.694676  1742 solver.cpp:218] Iteration 0 (0 iter/s, 0.103589s/5000 iters), loss = 8.57523
I0620 16:52:18.694720  1742 solver.cpp:237]     Train net output #0: ClassifyLoss = 0.14911 (* 1 = 0.14911 loss)
I0620 16:52:18.694727  1742 solver.cpp:237]     Train net output #1: LandmarkLoss = 7.73724 (* 1 = 7.73724 loss)
I0620 16:52:18.694751  1742 solver.cpp:237]     Train net output #2: RegressionLoss = 1.37777 (* 0.5 = 0.688886 loss)
I0620 16:52:18.694756  1742 solver.cpp:237]     Train net output #3: cls_Acc = 0.888889
I0620 16:52:18.694763  1742 sgd_solver.cpp:105] Iteration 0, lr = 1e-05
I0620 16:52:44.101646  1742 solver.cpp:447] Snapshotting to binary proto file ./models/_iter_5000.caffemodel
I0620 16:52:44.108917  1742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/_iter_5000.solverstate
I0620 16:52:44.117724  1742 solver.cpp:218] Iteration 5000 (196.673 iter/s, 25.4229s/5000 iters), loss = 1.26995
I0620 16:52:44.117769  1742 solver.cpp:237]     Train net output #0: ClassifyLoss = 0.801085 (* 1 = 0.801085 loss)
I0620 16:52:44.117775  1742 solver.cpp:237]     Train net output #1: LandmarkLoss = 0.347653 (* 1 = 0.347653 loss)
I0620 16:52:44.117780  1742 solver.cpp:237]     Train net output #2: RegressionLoss = 0.24242 (* 0.5 = 0.12121 loss)
I0620 16:52:44.117784  1742 solver.cpp:237]     Train net output #3: cls_Acc = 0.8
I0620 16:52:44.117789  1742 sgd_solver.cpp:105] Iteration 5000, lr = 1e-05
I0620 16:53:10.027454  1742 solver.cpp:447] Snapshotting to binary proto file ./models/_iter_10000.caffemodel
I0620 16:53:10.033797  1742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/_iter_10000.solverstate
I0620 16:53:10.042379  1742 solver.cpp:218] Iteration 10000 (192.868 iter/s, 25.9245s/5000 iters), loss = 0.385859
I0620 16:53:10.042423  1742 solver.cpp:237]     Train net output #0: ClassifyLoss = 0.0338494 (* 1 = 0.0338494 loss)
I0620 16:53:10.042445  1742 solver.cpp:237]     Train net output #1: LandmarkLoss = 0.251576 (* 1 = 0.251576 loss)
I0620 16:53:10.042450  1742 solver.cpp:237]     Train net output #2: RegressionLoss = 0.200869 (* 0.5 = 0.100434 loss)
I0620 16:53:10.042455  1742 solver.cpp:237]     Train net output #3: cls_Acc = 1
I0620 16:53:10.042459  1742 sgd_solver.cpp:105] Iteration 10000, lr = 1e-05
I0620 16:53:35.788657  1742 solver.cpp:447] Snapshotting to binary proto file ./models/_iter_15000.caffemodel
I0620 16:53:35.794981  1742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/_iter_15000.solverstate
I0620 16:53:35.803537  1742 solver.cpp:218] Iteration 15000 (194.092 iter/s, 25.761s/5000 iters), loss = 0.61019
I0620 16:53:35.803596  1742 solver.cpp:237]     Train net output #0: ClassifyLoss = 0.169656 (* 1 = 0.169656 loss)
I0620 16:53:35.803601  1742 solver.cpp:237]     Train net output #1: LandmarkLoss = 0.289716 (* 1 = 0.289716 loss)
I0620 16:53:35.803619  1742 solver.cpp:237]     Train net output #2: RegressionLoss = 0.301638 (* 0.5 = 0.150819 loss)
I0620 16:53:35.803623  1742 solver.cpp:237]     Train net output #3: cls_Acc = 0.875
I0620 16:53:35.803643  1742 sgd_solver.cpp:105] Iteration 15000, lr = 1e-05
I0620 16:54:01.284777  1742 solver.cpp:447] Snapshotting to binary proto file ./models/_iter_20000.caffemodel
I0620 16:54:01.291100  1742 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./models/_iter_20000.solverstate
I0620 16:54:01.296798  1742 solver.cpp:310] Iteration 20000, loss = 0.311086
I0620 16:54:01.296818  1742 solver.cpp:315] Optimization Done.
I0620 16:54:01.296820  1742 caffe.cpp:259] Optimization Done.